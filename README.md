# Next-Gen-Ai
A project on GAN Based Image Synthesis With Text Embedding
This project implements a Text-to-image generation pipeline using Generative adversial network(GANs)
# Project Overview
This project implements a Text-to-Image Generation pipeline using Generative Adversarial Networks (GANs). The system generates realistic images based on textual descriptions using deep learning techniques.The goal of this project is to bridge Natural Language Processing (NLP) and Computer Vision using GAN architectures.
# Objectives
 Convert text descriptions into vector embeddings
 Generate corresponding realistic images
 Train a GAN architecture (Generator + Discriminator)
 Evaluate image quality and training stability
# Model Architecture
The pipeline consists of:
1. Text Encoder
   Converts text descriptions into embeddings
2. Generator (GAN)
   Takes noise + text embedding
   Generates synthetic images
3. Discriminator
   Distinguishes between real and generated images
   Ensures text-image consistency
# Technologies Used
Python
NumPy
Matplotlib
Google Colab
Jupyter Noteboo---

# Results
Successfully generated images from text prompts
Improved image quality over training epochs
Demonstrated GAN training dynamics.
# Notebook Link
[https://colab.research.google.com/drive/1kuDNGNksHlyyEUkW7oukRWapNWzIMs03?usp=sharing])





## ðŸ“‚ Project Structure
